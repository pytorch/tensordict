


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>tensordict package &mdash; tensordict main documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="TensorDictBase" href="generated/tensordict.TensorDictBase.html" />
    <link rel="prev" title="API Reference" href="index.html" />
  <!-- Google Analytics -->
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=GTM-T8XT4PS"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'GTM-T8XT4PS');
    </script>
  
  <!-- End Google Analytics -->
  

  
  <script src="../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active docs-active">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
                  <span class="dropdown-title">torcharrow</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn about the PyTorch foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  main (0.0.post1+g021bdf1)
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/tensordict_shapes.html">Manipulating the shape of a TensorDict</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/tensordict_slicing.html">Slicing, Indexing, and Masking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/tensordict_keys.html">Manipulating the keys of a TensorDict</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/tensordict_preallocation.html">Pre-allocating memory with TensorDict</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/tensordict_memory.html">Simplifying PyTorch Memory Management with TensorDict</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/streamed_tensordict.html">Building tensordicts from streams</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/tensordict_module.html">TensorDictModule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/export.html">Exporting tensordict modules</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/data_fashion.html">Using TensorDict for datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/tensorclass_fashion.html">Using tensorclasses for datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/tensorclass_imagenet.html">Batched data loading with tensorclasses</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed.html">TensorDict in distributed settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fx.html">Tracing TensorDictModule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../saving.html">Saving TensorDict and tensorclass objects</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">API Reference</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="index.html">API Reference</a> &gt;</li>
        
      <li>tensordict package</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/reference/tensordict.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

          
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <section id="tensordict-package">
<h1>tensordict package<a class="headerlink" href="#tensordict-package" title="Permalink to this heading">Â¶</a></h1>
<p>The <a class="reference internal" href="generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorDict</span></code></a> class simplifies the process of passing multiple tensors
from module to module by packing them in a dictionary-like object that inherits features from
regular pytorch tensors.</p>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensordict.TensorDictBase.html#tensordict.TensorDictBase" title="tensordict.TensorDictBase"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorDictBase</span></code></a>()</p></td>
<td><p>TensorDictBase is an abstract parent class for TensorDicts, a torch.Tensor data container.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorDict</span></code></a>([source,Â batch_size,Â device,Â ...])</p></td>
<td><p>A batched dictionary of tensors.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensordict.LazyStackedTensorDict.html#tensordict.LazyStackedTensorDict" title="tensordict.LazyStackedTensorDict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LazyStackedTensorDict</span></code></a>(*tensordicts[,Â ...])</p></td>
<td><p>A Lazy stack of TensorDicts.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensordict.PersistentTensorDict.html#tensordict.PersistentTensorDict" title="tensordict.PersistentTensorDict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PersistentTensorDict</span></code></a>(*[,Â batch_size,Â ...])</p></td>
<td><p>Persistent TensorDict implementation.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensordict.TensorDictParams.html#tensordict.TensorDictParams" title="tensordict.TensorDictParams"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TensorDictParams</span></code></a>([parameters,Â no_convert,Â lock])</p></td>
<td><p>A Wrapper for TensorDictBase with Parameter Exposure.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensordict.get_defaults_to_none.html#tensordict.get_defaults_to_none" title="tensordict.get_defaults_to_none"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_defaults_to_none</span></code></a>([set_to_none])</p></td>
<td><p>Returns the status of <cite>get</cite> default value.</p></td>
</tr>
</tbody>
</table>
<section id="constructors-and-handlers">
<h2>Constructors and handlers<a class="headerlink" href="#constructors-and-handlers" title="Permalink to this heading">Â¶</a></h2>
<p>The library offers a few method to interact with other data structures such as numpy structured arrays, namedtuples or
h5 files. The library also exposes dedicated functions to manipulate tensordicts such as <code class="docutils literal notranslate"><span class="pre">save</span></code>, <code class="docutils literal notranslate"><span class="pre">load</span></code>, <code class="docutils literal notranslate"><span class="pre">stack</span></code>
or <code class="docutils literal notranslate"><span class="pre">cat</span></code>.</p>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensordict.cat.html#tensordict.cat" title="tensordict.cat"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cat</span></code></a>(input[,Â dim,Â out])</p></td>
<td><p>Concatenates tensordicts into a single tensordict along the given dimension.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensordict.default_is_leaf.html#tensordict.default_is_leaf" title="tensordict.default_is_leaf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">default_is_leaf</span></code></a>(cls)</p></td>
<td><p>Returns <code class="docutils literal notranslate"><span class="pre">True</span></code> if a type is not a tensor collection (tensordict or tensorclass).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensordict.from_any.html#tensordict.from_any" title="tensordict.from_any"><code class="xref py py-obj docutils literal notranslate"><span class="pre">from_any</span></code></a>(obj,Â *[,Â auto_batch_size,Â ...])</p></td>
<td><p>Converts any object to a TensorDict.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensordict.from_consolidated.html#tensordict.from_consolidated" title="tensordict.from_consolidated"><code class="xref py py-obj docutils literal notranslate"><span class="pre">from_consolidated</span></code></a>(filename)</p></td>
<td><p>Reconstructs a tensordict from a consolidated file.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensordict.from_dict.html#tensordict.from_dict" title="tensordict.from_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">from_dict</span></code></a>(d,Â *[,Â auto_batch_size,Â ...])</p></td>
<td><p>Converts a dictionary to a TensorDict.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensordict.from_h5.html#tensordict.from_h5" title="tensordict.from_h5"><code class="xref py py-obj docutils literal notranslate"><span class="pre">from_h5</span></code></a>(h5_file,Â *[,Â auto_batch_size,Â ...])</p></td>
<td><p>Converts an HDF5 file to a TensorDict.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensordict.from_module.html#tensordict.from_module" title="tensordict.from_module"><code class="xref py py-obj docutils literal notranslate"><span class="pre">from_module</span></code></a>(module[,Â as_module,Â lock,Â ...])</p></td>
<td><p>Copies the params and buffers of a module in a tensordict.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensordict.from_modules.html#tensordict.from_modules" title="tensordict.from_modules"><code class="xref py py-obj docutils literal notranslate"><span class="pre">from_modules</span></code></a>(*modules[,Â as_module,Â lock,Â ...])</p></td>
<td><p>Retrieves the parameters of several modules for ensebmle learning/feature of expects applications through vmap.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensordict.from_namedtuple.html#tensordict.from_namedtuple" title="tensordict.from_namedtuple"><code class="xref py py-obj docutils literal notranslate"><span class="pre">from_namedtuple</span></code></a>(named_tuple,Â *[,Â ...])</p></td>
<td><p>Converts a namedtuple to a TensorDict.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensordict.from_pytree.html#tensordict.from_pytree" title="tensordict.from_pytree"><code class="xref py py-obj docutils literal notranslate"><span class="pre">from_pytree</span></code></a>(pytree,Â *[,Â batch_size,Â ...])</p></td>
<td><p>Converts a pytree to a TensorDict instance.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensordict.from_struct_array.html#tensordict.from_struct_array" title="tensordict.from_struct_array"><code class="xref py py-obj docutils literal notranslate"><span class="pre">from_struct_array</span></code></a>(struct_array,Â *[,Â ...])</p></td>
<td><p>Converts a structured numpy array to a TensorDict.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensordict.from_tuple.html#tensordict.from_tuple" title="tensordict.from_tuple"><code class="xref py py-obj docutils literal notranslate"><span class="pre">from_tuple</span></code></a>(obj,Â *[,Â auto_batch_size,Â ...])</p></td>
<td><p>Converts a tuple to a TensorDict.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensordict.fromkeys.html#tensordict.fromkeys" title="tensordict.fromkeys"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fromkeys</span></code></a>(keys[,Â value])</p></td>
<td><p>Creates a tensordict from a list of keys and a single value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensordict.is_batchedtensor.html#tensordict.is_batchedtensor" title="tensordict.is_batchedtensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">is_batchedtensor</span></code></a>(arg0)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensordict.is_leaf_nontensor.html#tensordict.is_leaf_nontensor" title="tensordict.is_leaf_nontensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">is_leaf_nontensor</span></code></a>(cls)</p></td>
<td><p>Returns <code class="docutils literal notranslate"><span class="pre">True</span></code> if a type is not a tensor collection (tensordict or tensorclass) or is a non-tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensordict.lazy_stack.html#tensordict.lazy_stack" title="tensordict.lazy_stack"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lazy_stack</span></code></a>(input[,Â dim,Â out])</p></td>
<td><p>Creates a lazy stack of tensordicts.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensordict.load.html#tensordict.load" title="tensordict.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(prefix[,Â device,Â non_blocking,Â out])</p></td>
<td><p>Loads a tensordict from disk.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensordict.load_memmap.html#tensordict.load_memmap" title="tensordict.load_memmap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_memmap</span></code></a>(prefix[,Â device,Â non_blocking,Â out])</p></td>
<td><p>Loads a memory-mapped tensordict from disk.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensordict.maybe_dense_stack.html#tensordict.maybe_dense_stack" title="tensordict.maybe_dense_stack"><code class="xref py py-obj docutils literal notranslate"><span class="pre">maybe_dense_stack</span></code></a>(input[,Â dim,Â out])</p></td>
<td><p>Attempts to make a dense stack of tensordicts, and falls back on lazy stack when required..</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensordict.memmap.html#tensordict.memmap" title="tensordict.memmap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">memmap</span></code></a>(data[,Â prefix,Â copy_existing,Â ...])</p></td>
<td><p>Writes all tensors onto a corresponding memory-mapped Tensor in a new tensordict.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensordict.save.html#tensordict.save" title="tensordict.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(data[,Â prefix,Â copy_existing,Â ...])</p></td>
<td><p>Saves the tensordict to disk.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensordict.stack.html#tensordict.stack" title="tensordict.stack"><code class="xref py py-obj docutils literal notranslate"><span class="pre">stack</span></code></a>(input[,Â dim,Â out])</p></td>
<td><p>Stacks tensordicts into a single tensordict along the given dimension.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="tensordict-as-a-context-manager">
<h2>TensorDict as a context manager<a class="headerlink" href="#tensordict-as-a-context-manager" title="Permalink to this heading">Â¶</a></h2>
<p><a class="reference internal" href="generated/tensordict.TensorDict.html#tensordict.TensorDict" title="tensordict.TensorDict"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorDict</span></code></a> can be used as a context manager in situations
where an action has to be done and then undone. This include temporarily
locking/unlocking a tensordict</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span><span class="o">.</span><span class="n">lock_</span><span class="p">()</span>  <span class="c1"># data.set will result in an exception</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">data</span><span class="o">.</span><span class="n">unlock_</span><span class="p">():</span>
<span class="gp">... </span>    <span class="n">data</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;key&quot;</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">data</span><span class="o">.</span><span class="n">is_locked</span><span class="p">()</span>
</pre></div>
</div>
<p>or to execute functional calls with a TensorDict instance containing the
parameters and buffers of a model:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">params</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="o">.</span><span class="n">from_module</span><span class="p">(</span><span class="n">module</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">params</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">params</span><span class="o">.</span><span class="n">to_module</span><span class="p">(</span><span class="n">module</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">y</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>In the first example, we can modify the tensordict <cite>data</cite> because we have
temporarily unlocked it. In the second example, we populate the module with the
parameters and buffers contained in the <cite>params</cite> tensordict instance, and reset
the original parameters after this call is completed.</p>
</section>
<section id="memory-mapped-tensors">
<h2>Memory-mapped tensors<a class="headerlink" href="#memory-mapped-tensors" title="Permalink to this heading">Â¶</a></h2>
<p><cite>tensordict</cite> offers the <a class="reference internal" href="generated/tensordict.MemoryMappedTensor.html#tensordict.MemoryMappedTensor" title="tensordict.MemoryMappedTensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">MemoryMappedTensor</span></code></a> primitive which
allows you to work with tensors stored in physical memory in a handy way.
The main advantages of <a class="reference internal" href="generated/tensordict.MemoryMappedTensor.html#tensordict.MemoryMappedTensor" title="tensordict.MemoryMappedTensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">MemoryMappedTensor</span></code></a>
are its ease of construction (no need to handle the storage of a tensor),
the possibility to work with big contiguous data that would not fit in memory,
an efficient (de)serialization across processes and efficient indexing of
stored tensors.</p>
<p>If all workers have access to the same storage (both in multiprocess and distributed
settings), passing a <a class="reference internal" href="generated/tensordict.MemoryMappedTensor.html#tensordict.MemoryMappedTensor" title="tensordict.MemoryMappedTensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">MemoryMappedTensor</span></code></a>
will just consist in passing a reference to a file on disk plus a bunch of
extra meta-data for reconstructing it. The same goes with indexed memory-mapped
tensors as long as the data-pointer of their storage is the same as the original
one.</p>
<p>Indexing memory-mapped tensors is much faster than loading several independent files from
the disk and does not require to load the full content of the array in memory.
However, physical storage of PyTorch tensors should not be any different:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">my_images</span> <span class="o">=</span> <span class="n">MemoryMappedTensor</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">1_000_000</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">480</span><span class="p">,</span> <span class="mi">480</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">unint8</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">mini_batch</span> <span class="o">=</span> <span class="n">my_images</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>  <span class="c1"># just reads the first 10 images of the dataset</span>
</pre></div>
</div>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensordict.MemoryMappedTensor.html#tensordict.MemoryMappedTensor" title="tensordict.MemoryMappedTensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MemoryMappedTensor</span></code></a>(source,Â *[,Â dtype,Â ...])</p></td>
<td><p>A Memory-mapped Tensor.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="pointwise-operations">
<h2>Pointwise Operations<a class="headerlink" href="#pointwise-operations" title="Permalink to this heading">Â¶</a></h2>
<p>Tensordict supports various pointwise operations, allowing you to perform element-wise computations on the tensors
stored within it. These operations are similar to those performed on regular PyTorch tensors.</p>
<section id="supported-operations">
<h3>Supported Operations<a class="headerlink" href="#supported-operations" title="Permalink to this heading">Â¶</a></h3>
<p>The following pointwise operations are currently supported:</p>
<ul class="simple">
<li><p>Left and right addition (<cite>+</cite>)</p></li>
<li><p>Left and right subtraction (<cite>-</cite>)</p></li>
<li><p>Left and right multiplication (<cite>*</cite>)</p></li>
<li><p>Left and right division (<cite>/</cite>)</p></li>
<li><p>Left power (<cite>**</cite>)</p></li>
</ul>
<p>Many other ops, like <a class="reference internal" href="generated/tensordict.TensorDict.html#tensordict.TensorDict.clamp" title="tensordict.TensorDict.clamp"><code class="xref py py-meth docutils literal notranslate"><span class="pre">clamp()</span></code></a>, <a class="reference internal" href="generated/tensordict.TensorDict.html#tensordict.TensorDict.sqrt" title="tensordict.TensorDict.sqrt"><code class="xref py py-meth docutils literal notranslate"><span class="pre">sqrt()</span></code></a> etc. are supported.</p>
</section>
<section id="performing-pointwise-operations">
<h3>Performing Pointwise Operations<a class="headerlink" href="#performing-pointwise-operations" title="Permalink to this heading">Â¶</a></h3>
<p>You can perform pointwise operations between two Tensordicts or between a Tensordict and a tensor/scalar value.</p>
<section id="example-1-tensordict-tensordict-operation">
<h4>Example 1: Tensordict-Tensordict Operation<a class="headerlink" href="#example-1-tensordict-tensordict-operation" title="Permalink to this heading">Â¶</a></h4>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">tensordict</span><span class="w"> </span><span class="kn">import</span> <span class="n">TensorDict</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">td1</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">a</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">b</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">c</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">batch_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">td2</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">a</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">b</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">c</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">batch_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">td1</span> <span class="o">*</span> <span class="n">td2</span>
</pre></div>
</div>
<p>In this example, the * operator is applied element-wise to the corresponding tensors in td1 and td2.</p>
</section>
<section id="example-2-tensordict-tensor-operation">
<h4>Example 2: Tensordict-Tensor Operation<a class="headerlink" href="#example-2-tensordict-tensor-operation" title="Permalink to this heading">Â¶</a></h4>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">tensordict</span><span class="w"> </span><span class="kn">import</span> <span class="n">TensorDict</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">td</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">a</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">b</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">c</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">batch_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">td</span> <span class="o">*</span> <span class="n">tensor</span>
</pre></div>
</div>
<p>ere, the * operator is applied element-wise to each tensor in td and the provided tensor. The tensor is broadcasted to match the shape of each tensor in the Tensordict.</p>
</section>
<section id="example-3-tensordict-scalar-operation">
<h4>Example 3: Tensordict-Scalar Operation<a class="headerlink" href="#example-3-tensordict-scalar-operation" title="Permalink to this heading">Â¶</a></h4>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">tensordict</span><span class="w"> </span><span class="kn">import</span> <span class="n">TensorDict</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">td</span> <span class="o">=</span> <span class="n">TensorDict</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">a</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">b</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">c</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">batch_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scalar</span> <span class="o">=</span> <span class="mf">2.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">td</span> <span class="o">*</span> <span class="n">scalar</span>
</pre></div>
</div>
<p>In this case, the * operator is applied element-wise to each tensor in td and the provided scalar.</p>
</section>
</section>
<section id="broadcasting-rules">
<h3>Broadcasting Rules<a class="headerlink" href="#broadcasting-rules" title="Permalink to this heading">Â¶</a></h3>
<p>When performing pointwise operations between a Tensordict and a tensor/scalar, the tensor/scalar is broadcasted to match
the shape of each tensor in the Tensordict: the tensor is broadcast on the left to match the tensordict shape, then
individually broadcast on the right to match the tensors shapes. This follows the standard broadcasting rules used in
PyTorch if one thinks of the <code class="docutils literal notranslate"><span class="pre">TensorDict</span></code> as a single tensor instance.</p>
<p>For example, if you have a Tensordict with tensors of shape <code class="docutils literal notranslate"><span class="pre">(3,</span> <span class="pre">4)</span></code> and you multiply it by a tensor of shape <code class="docutils literal notranslate"><span class="pre">(4,)</span></code>,
the tensor will be broadcasted to shape (3, 4) before the operation is applied. If the tensordict contains a tensor of
shape <code class="docutils literal notranslate"><span class="pre">(3,</span> <span class="pre">4,</span> <span class="pre">5)</span></code>, the tensor used for the multiplication will be broadcast to <code class="docutils literal notranslate"><span class="pre">(3,</span> <span class="pre">4,</span> <span class="pre">5)</span></code> on the right for that
multiplication.</p>
<p>If the pointwise operation is executed across multiple tensordicts and their batch-size differ, they will be
broadcasted to a common shape.</p>
</section>
<section id="efficiency-of-pointwise-operations">
<h3>Efficiency of pointwise operations<a class="headerlink" href="#efficiency-of-pointwise-operations" title="Permalink to this heading">Â¶</a></h3>
<p>When possible, <code class="docutils literal notranslate"><span class="pre">torch._foreach_&lt;op&gt;</span></code> fused kernels will be used to speed up the computation of the pointwise
operation.</p>
</section>
<section id="handling-missing-entries">
<h3>Handling Missing Entries<a class="headerlink" href="#handling-missing-entries" title="Permalink to this heading">Â¶</a></h3>
<p>When performing pointwise operations between two Tensordicts, they must have the same keys.
Some operations, like <a class="reference internal" href="generated/tensordict.TensorDict.html#tensordict.TensorDict.add" title="tensordict.TensorDict.add"><code class="xref py py-meth docutils literal notranslate"><span class="pre">add()</span></code></a>, have a <code class="docutils literal notranslate"><span class="pre">default</span></code> keyword argument that can be used
to operate with tensordict with exclusive entries.
If <code class="docutils literal notranslate"><span class="pre">default=None</span></code> (the default), the two Tensordicts must have exactly matching key sets.
If <code class="docutils literal notranslate"><span class="pre">default=&quot;intersection&quot;</span></code>, only the intersecting key sets will be considered, and other keys will be ignored.
In all other cases, <code class="docutils literal notranslate"><span class="pre">default</span></code> will be used for all missing entries on both sides of the operation.</p>
</section>
</section>
<section id="utils">
<h2>Utils<a class="headerlink" href="#utils" title="Permalink to this heading">Â¶</a></h2>
<table class="autosummary longtable docutils # Necessary for the table generated by autosummary to look decent align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensordict.utils.expand_as_right.html#tensordict.utils.expand_as_right" title="tensordict.utils.expand_as_right"><code class="xref py py-obj docutils literal notranslate"><span class="pre">utils.expand_as_right</span></code></a>(tensor,Â dest)</p></td>
<td><p>Expand a tensor on the right to match another tensor shape.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensordict.utils.expand_right.html#tensordict.utils.expand_right" title="tensordict.utils.expand_right"><code class="xref py py-obj docutils literal notranslate"><span class="pre">utils.expand_right</span></code></a>(tensor,Â shape)</p></td>
<td><p>Expand a tensor on the right to match a desired shape.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensordict.utils.isin.html#tensordict.utils.isin" title="tensordict.utils.isin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">utils.isin</span></code></a>(input,Â reference,Â key[,Â dim])</p></td>
<td><p>Tests if each element of <code class="docutils literal notranslate"><span class="pre">key</span></code> in input <code class="docutils literal notranslate"><span class="pre">dim</span></code> is also present in the reference.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensordict.utils.remove_duplicates.html#tensordict.utils.remove_duplicates" title="tensordict.utils.remove_duplicates"><code class="xref py py-obj docutils literal notranslate"><span class="pre">utils.remove_duplicates</span></code></a>(input,Â key[,Â dim,Â ...])</p></td>
<td><p>Removes indices duplicated in <cite>key</cite> along the specified dimension.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensordict.capture_non_tensor_stack.html#tensordict.capture_non_tensor_stack" title="tensordict.capture_non_tensor_stack"><code class="xref py py-obj docutils literal notranslate"><span class="pre">capture_non_tensor_stack</span></code></a>([allow_none])</p></td>
<td><p>Get the current setting for capturing non-tensor stacks.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensordict.dense_stack_tds.html#tensordict.dense_stack_tds" title="tensordict.dense_stack_tds"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dense_stack_tds</span></code></a>(td_list[,Â dim])</p></td>
<td><p>Densely stack a list of <a class="reference internal" href="generated/tensordict.TensorDictBase.html#tensordict.TensorDictBase" title="tensordict.TensorDictBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorDictBase</span></code></a> objects (or a <a class="reference internal" href="generated/tensordict.LazyStackedTensorDict.html#tensordict.LazyStackedTensorDict" title="tensordict.LazyStackedTensorDict"><code class="xref py py-class docutils literal notranslate"><span class="pre">LazyStackedTensorDict</span></code></a>) given that they have the same structure.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensordict.is_batchedtensor.html#tensordict.is_batchedtensor" title="tensordict.is_batchedtensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">is_batchedtensor</span></code></a>(arg0)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensordict.is_tensor_collection.html#tensordict.is_tensor_collection" title="tensordict.is_tensor_collection"><code class="xref py py-obj docutils literal notranslate"><span class="pre">is_tensor_collection</span></code></a>(datatype)</p></td>
<td><p>Checks if a data object or a type is a tensor container from the tensordict lib.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensordict.lazy_legacy.html#tensordict.lazy_legacy" title="tensordict.lazy_legacy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lazy_legacy</span></code></a>([allow_none])</p></td>
<td><p>Returns <cite>True</cite> if lazy representations will be used for selected methods.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensordict.make_tensordict.html#tensordict.make_tensordict" title="tensordict.make_tensordict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_tensordict</span></code></a>([input_dict,Â batch_size,Â ...])</p></td>
<td><p>Returns a TensorDict created from the keyword arguments or an input dictionary.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensordict.merge_tensordicts.html#tensordict.merge_tensordicts" title="tensordict.merge_tensordicts"><code class="xref py py-obj docutils literal notranslate"><span class="pre">merge_tensordicts</span></code></a>(*tensordicts[,Â callback_exist])</p></td>
<td><p>Merges tensordicts together.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensordict.pad.html#tensordict.pad" title="tensordict.pad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pad</span></code></a>(tensordict,Â pad_size[,Â value])</p></td>
<td><p>Pads all tensors in a tensordict along the batch dimensions with a constant value, returning a new tensordict.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensordict.pad_sequence.html#tensordict.pad_sequence" title="tensordict.pad_sequence"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pad_sequence</span></code></a>(list_of_tensordicts[,Â pad_dim,Â ...])</p></td>
<td><p>Pads a list of tensordicts in order for them to be stacked together in a contiguous format.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensordict.parse_tensor_dict_string.html#tensordict.parse_tensor_dict_string" title="tensordict.parse_tensor_dict_string"><code class="xref py py-obj docutils literal notranslate"><span class="pre">parse_tensor_dict_string</span></code></a>(s)</p></td>
<td><p>Parse a TensorDict repr to a TensorDict.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensordict.set_capture_non_tensor_stack.html#tensordict.set_capture_non_tensor_stack" title="tensordict.set_capture_non_tensor_stack"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_capture_non_tensor_stack</span></code></a>(mode)</p></td>
<td><p>A context manager or decorator to control whether identical non-tensor data should be stacked into a single NonTensorData object or a NonTensorStack.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensordict.set_lazy_legacy.html#tensordict.set_lazy_legacy" title="tensordict.set_lazy_legacy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_lazy_legacy</span></code></a>(mode)</p></td>
<td><p>Sets the behaviour of some methods to a lazy transform.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/tensordict.set_list_to_stack.html#tensordict.set_list_to_stack" title="tensordict.set_list_to_stack"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_list_to_stack</span></code></a>(mode)</p></td>
<td><p>Context manager and decorator to control the behavior of list handling in TensorDict.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/tensordict.list_to_stack.html#tensordict.list_to_stack" title="tensordict.list_to_stack"><code class="xref py py-obj docutils literal notranslate"><span class="pre">list_to_stack</span></code></a>([allow_none])</p></td>
<td><p>Retrieves the current setting for list-to-stack conversion in TensorDict.</p></td>
</tr>
</tbody>
</table>
</section>
</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="generated/tensordict.TensorDictBase.html" class="btn btn-neutral float-right" title="TensorDictBase" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="index.html" class="btn btn-neutral" title="API Reference" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Meta.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">tensordict package</a><ul>
<li><a class="reference internal" href="#constructors-and-handlers">Constructors and handlers</a></li>
<li><a class="reference internal" href="#tensordict-as-a-context-manager">TensorDict as a context manager</a></li>
<li><a class="reference internal" href="#memory-mapped-tensors">Memory-mapped tensors</a></li>
<li><a class="reference internal" href="#pointwise-operations">Pointwise Operations</a><ul>
<li><a class="reference internal" href="#supported-operations">Supported Operations</a></li>
<li><a class="reference internal" href="#performing-pointwise-operations">Performing Pointwise Operations</a><ul>
<li><a class="reference internal" href="#example-1-tensordict-tensordict-operation">Example 1: Tensordict-Tensordict Operation</a></li>
<li><a class="reference internal" href="#example-2-tensordict-tensor-operation">Example 2: Tensordict-Tensor Operation</a></li>
<li><a class="reference internal" href="#example-3-tensordict-scalar-operation">Example 3: Tensordict-Scalar Operation</a></li>
</ul>
</li>
<li><a class="reference internal" href="#broadcasting-rules">Broadcasting Rules</a></li>
<li><a class="reference internal" href="#efficiency-of-pointwise-operations">Efficiency of pointwise operations</a></li>
<li><a class="reference internal" href="#handling-missing-entries">Handling Missing Entries</a></li>
</ul>
</li>
<li><a class="reference internal" href="#utils">Utils</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
         <script src="../_static/jquery.js"></script>
         <script src="../_static/underscore.js"></script>
         <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../_static/doctools.js"></script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>

        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>Â© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title" class="active">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/torcharrow">torcharrow</a>
            </li>

            <li>
              <a href="https://pytorch.org/data">TorchData</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchrec">TorchRec</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>

           <ul class="resources-mobile-menu-items">

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>

            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>