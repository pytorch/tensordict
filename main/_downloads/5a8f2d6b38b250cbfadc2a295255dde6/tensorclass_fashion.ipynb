{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Using tensorclasses for datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this tutorial we demonstrate how tensorclasses can be used to\nefficiently and transparently load and manage data inside a training\npipeline. The tutorial is based heavily on the [PyTorch Quickstart\nTutorial](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html)_,\nbut modified to demonstrate use of tensorclass. See the related tutorial using\n``TensorDict``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport torch.nn as nn\n\nfrom tensordict import MemoryMappedTensor, tensorclass\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The ``torchvision.datasets`` module contains a number of convenient pre-prepared\ndatasets. In this tutorial we'll use the relatively simple FashionMNIST dataset. Each\nimage is an item of clothing, the objective is to classify the type of clothing in\nthe image (e.g. \"Bag\", \"Sneaker\" etc.).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "training_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=True,\n    download=True,\n    transform=ToTensor(),\n)\ntest_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=False,\n    download=True,\n    transform=ToTensor(),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tensorclasses are dataclasses that expose dedicated tensor methods over\nits contents much like ``TensorDict``. They are a good choice when the\nstructure of the data you want to store is fixed and predictable.\n\nAs well as specifying the contents, we can also encapsulate related\nlogic as custom methods when defining the class. In this case we'll\nwrite a ``from_dataset`` classmethod that takes a dataset as input and\ncreates a tensorclass containing the data from the dataset. We create\nmemory-mapped tensors to hold the data. This will allow us to\nefficiently load batches of transformed data from disk rather than\nrepeatedly load and transform individual images.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "@tensorclass\nclass FashionMNISTData:\n    images: torch.Tensor\n    targets: torch.Tensor\n\n    @classmethod\n    def from_dataset(cls, dataset, device=None):\n        data = cls(\n            images=MemoryMappedTensor.empty(\n                (len(dataset), *dataset[0][0].squeeze().shape), dtype=torch.float32\n            ),\n            targets=MemoryMappedTensor.empty((len(dataset),), dtype=torch.int64),\n            batch_size=[len(dataset)],\n            device=device,\n        )\n        for i, (image, target) in enumerate(dataset):\n            data[i] = cls(images=image, targets=torch.tensor(target), batch_size=[])\n        return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will create two tensorclasses, one each for the training and test data. Note that\nwe incur some overhead here as we are looping over the entire dataset, transforming\nand saving to disk.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "training_data_tc = FashionMNISTData.from_dataset(training_data, device=device)\ntest_data_tc = FashionMNISTData.from_dataset(test_data, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DataLoaders\n\nWe'll create DataLoaders from the ``torchvision``-provided Datasets, as\nwell as from our memory-mapped TensorDicts.\n\nSince ``TensorDict`` implements ``__len__`` and ``__getitem__`` (and\nalso ``__getitems__``) we can use it like a map-style Dataset and create\na ``DataLoader`` directly from it. Note that because ``TensorDict`` can\nalready handle batched indices, there is no need for collation, so we\npass the identity function as ``collate_fn``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n\ntrain_dataloader = DataLoader(training_data, batch_size=batch_size)  # noqa: TOR401\ntest_dataloader = DataLoader(test_data, batch_size=batch_size)  # noqa: TOR401\n\ntrain_dataloader_tc = DataLoader(  # noqa: TOR401\n    training_data_tc, batch_size=batch_size, collate_fn=lambda x: x\n)\ntest_dataloader_tc = DataLoader(  # noqa: TOR401\n    test_data_tc, batch_size=batch_size, collate_fn=lambda x: x\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model\n\nWe use the same model from the\n[Quickstart Tutorial](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html)_.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(28 * 28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10),\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits\n\n\nmodel = Net().to(device)\nmodel_tc = Net().to(device)\nmodel, model_tc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimizing the parameters\n\nWe'll optimise the parameters of the model using stochastic gradient descent and\ncross-entropy loss.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\noptimizer_tc = torch.optim.SGD(model_tc.parameters(), lr=1e-3)\n\n\ndef train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.train()\n\n    for batch, (X, y) in enumerate(dataloader):\n        X, y = X.to(device), y.to(device)\n\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if batch % 100 == 0:\n            loss, current = loss.item(), batch * len(X)\n            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The training loop for our tensorclass-based DataLoader is very similar, we just\nadjust how we unpack the data to the more explicit attribute-based retrieval offered\nby the tensorclass. The ``.contiguous()`` method loads the data stored in the memmap\ntensor.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def train_tc(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.train()\n\n    for batch, data in enumerate(dataloader):\n        X, y = data.images.contiguous(), data.targets.contiguous()\n\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if batch % 100 == 0:\n            loss, current = loss.item(), batch * len(X)\n            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n\n\ndef test(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n\n            pred = model(X)\n\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n\n    test_loss /= num_batches\n    correct /= size\n\n    print(\n        f\"Test Error: \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\"\n    )\n\n\ndef test_tc(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for batch in dataloader:\n            X, y = batch.images.contiguous(), batch.targets.contiguous()\n\n            pred = model(X)\n\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n\n    test_loss /= num_batches\n    correct /= size\n\n    print(\n        f\"Test Error: \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\"\n    )\n\n\nfor d in train_dataloader_tc:\n    print(d)\n    break\n\nimport time\n\nt0 = time.time()\nepochs = 5\nfor t in range(epochs):\n    print(f\"Epoch {t + 1}\\n-------------------------\")\n    train_tc(train_dataloader_tc, model_tc, loss_fn, optimizer_tc)\n    test_tc(test_dataloader_tc, model_tc, loss_fn)\nprint(f\"Tensorclass training done! time: {time.time() - t0: 4.4f} s\")\n\nt0 = time.time()\nepochs = 5\nfor t in range(epochs):\n    print(f\"Epoch {t + 1}\\n-------------------------\")\n    train(train_dataloader, model, loss_fn, optimizer)\n    test(test_dataloader, model, loss_fn)\nprint(f\"Training done! time: {time.time() - t0: 4.4f} s\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}