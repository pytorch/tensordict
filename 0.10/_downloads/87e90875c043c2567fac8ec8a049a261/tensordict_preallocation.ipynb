{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Pre-allocating memory with TensorDict\n**Author**: [Tom Begley](https://github.com/tcbegley)\n\nIn this tutorial you will learn how to take advantage of memory pre-allocation in\n:class:`~.TensorDict`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Suppose that we have a function that returns a :class:`~.TensorDict`\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom tensordict.tensordict import TensorDict\n\n\ndef make_tensordict():\n    return TensorDict({\"a\": torch.rand(3), \"b\": torch.rand(3, 4)}, [3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Perhaps we want to call this function multiple times and use the results to populate\na single :class:`~.TensorDict`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "N = 10\ntensordict = TensorDict({}, batch_size=[N, 3])\n\nfor i in range(N):\n    tensordict[i] = make_tensordict()\n\nprint(tensordict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Because we have specified the ``batch_size`` of ``tensordict``, during the first\niteration of the loop we populate ``tensordict`` with empty tensors whose first\ndimension is size ``N``, and whose remaining dimensions are determined by the return\nvalue of ``make_tensordict``. In the above example, we pre-allocate an array of zeros\nof size ``torch.Size([10, 3])`` for the key ``\"a\"``, and an array size\n``torch.Size([10, 3, 4])`` for the key ``\"b\"``. Subsequent iterations of the loop are\nwritten in place. As a result, if not all values are filled, they get the default\nvalue of zero.\n\nLet us demonstrate what is going on by stepping through the above loop. We first\ninitialise an empty :class:`~.TensorDict`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "N = 10\ntensordict = TensorDict({}, batch_size=[N, 3])\nprint(tensordict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After the first iteration, ``tensordict`` has been prepopulated with tensors for both\n``\"a\"`` and ``\"b\"``. These tensors contain zeros except for the first row which we\nhave assigned random values to.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "random_tensordict = make_tensordict()\ntensordict[0] = random_tensordict\n\nassert (tensordict[1:] == 0).all()\nassert (tensordict[0] == random_tensordict).all()\n\nprint(tensordict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Subsequent iterations, we update the pre-allocated tensors in-place.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "a = tensordict[\"a\"]\nrandom_tensordict = make_tensordict()\ntensordict[1] = random_tensordict\n\n# the same tensor is stored under \"a\", but the values have been updated\nassert tensordict[\"a\"] is a\nassert (tensordict[:2] != 0).all()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}