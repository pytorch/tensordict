{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Functionalizing TensorDictModule\nIn this tutorial you will learn how to use :class:`~.TensorDictModule` in conjunction\nwith functorch to create functionlized modules.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before we take a look at the functional utilities in :mod:`tensordict.nn`, let us\nreintroduce one of the example modules from the :class:`~.TensorDictModule` tutorial.\n\nWe'll create a simple module that has two linear layers, which share the input and\nreturn separate outputs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import functorch\nimport torch\nimport torch.nn as nn\nfrom tensordict import TensorDict\nfrom tensordict.nn import TensorDictModule\n\n\nclass MultiHeadLinear(nn.Module):\n    def __init__(self, in_1, out_1, out_2):\n        super().__init__()\n        self.linear_1 = nn.Linear(in_1, out_1)\n        self.linear_2 = nn.Linear(in_1, out_2)\n\n    def forward(self, x):\n        return self.linear_1(x), self.linear_2(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now create a :class:`~.TensorDictModule` that will read the input from a key\n``\"a\"``, and write to the keys ``\"output_1\"`` and ``\"output_2\"``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "splitlinear = TensorDictModule(\n    MultiHeadLinear(3, 4, 10), in_keys=[\"a\"], out_keys=[\"output_1\", \"output_2\"]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ordinarily we would use this module by simply calling it on a :class:`~.TensorDict`\nwith the required input keys.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tensordict = TensorDict({\"a\": torch.randn(5, 3)}, batch_size=[5])\nsplitlinear(tensordict)\nprint(tensordict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However, we can also use :func:`functorch.make_functional_with_buffers` in order to\nfunctionalise the module.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "func, params, buffers = functorch.make_functional_with_buffers(splitlinear)\nprint(func(params, buffers, tensordict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This can be used with the vmap operator. For example, we use 3 replicas of the\nparams and buffers and execute a vectorized map over these for a single batch\nof data:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "params_expand = [p.expand(3, *p.shape) for p in params]\nbuffers_expand = [p.expand(3, *p.shape) for p in buffers]\nprint(torch.vmap(func, (0, 0, None))(params_expand, buffers_expand, tensordict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also use the native :func:`make_functional <tensordict.nn.make_functional>`\nfunction from :mod:`tensordict.nn``, which modifies the module to make it accept the\nparameters as regular inputs:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from tensordict.nn import make_functional\n\ntensordict = TensorDict({\"a\": torch.randn(5, 3)}, batch_size=[5])\n\nnum_models = 10\nmodel = TensorDictModule(nn.Linear(3, 4), in_keys=[\"a\"], out_keys=[\"output\"])\nparams = make_functional(model)\n# we stack two groups of parameters to show the vmap usage:\nparams = torch.stack([params, params.apply(lambda x: torch.zeros_like(x))], 0)\nresult_td = torch.vmap(model, (None, 0))(tensordict, params)\nprint(\"the output tensordict shape is: \", result_td.shape)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}